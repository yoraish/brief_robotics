{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory optimization\n",
    "\n",
    "As a robot moves around the world, it can accumulates readings of its own motion. _\"I have moved a meters forward!\"_, a robot may exclaim after querying a sensor. _\"One meter forward and twenty to the left!\"_, after another reading. And you get how that goes.\n",
    "\n",
    "After some time, a robot may have collected a _sequence_ of measurements that, when put together, are representative of its entire trajectory. However, there is an immediate danger in this formulation! If a single measurement is wrong, the rest will carry over its error.\n",
    "\n",
    "For example, if we have the readings:\n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "\n",
    "the robot believes that it drew a square and got back to its starting position. \n",
    "\n",
    "However, if the readings change to \n",
    "\n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate` **45 degree to the left**, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "\n",
    "then the robot believes that it traveled to a point to the left of its starting point. This is called odometry drift. It is the scenario where error in odometry readings get carried over to the next position estimates.\n",
    "\n",
    "Hope is not all lost, however! Given additional information, robots can correct the estimates of their position in the world and also correct backwards (smooth) their entire trajectory. \n",
    "Back to our simple example, if the robot knew somehow that the end position of its third motion was one meter to the left of the origin, then it would get there corrected readings:\n",
    "\n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "* ~~`forward 1m and rotate` 45 degree to the left~~  **at one meter to the left of the origin and facing it** \n",
    "* `forward 1m and rotate 90 degree to the left`, \n",
    "\n",
    "and the robot would believe that it is back at the initial position and also that it has turned 90 degrees in its third motion.\n",
    "\n",
    "In this section we'll be exploring this problem, which we call **trajectory optimization**, in depth.\n",
    "\n",
    "We'll be \n",
    "* Discussing rigid transformations in 2-dimensions.\n",
    "* Discussing landmark observations.\n",
    "* Discussing optimization problems in general.\n",
    "* Formalizing the trajectory optimization problem.\n",
    "* Solving the optimization problem with GTSAM.\n",
    "\n",
    "Let's get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO add figure for odometry drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rigid Transformations in 2D\n",
    "\n",
    "To converse about motion and localization in robotics it is helpful to agree on a couple of common conventions.\n",
    "\n",
    "## **Directions**\n",
    "\n",
    "We'll adopt the right-handed coordinate system for our discussion.\n",
    "* The front of the robot faces the positive $x$ direction.\n",
    "* The left side of the robot faces the positive $y$ direction.\n",
    "* The top of the robot faces the positive $z$ direction. Since we operate in two dimensions, we care less for this axis right now.\n",
    "* A positive rotation angle $\\theta$ is according to the right-hand-rule, with the thumb pointing towards the $z$ direction and zero being on the $x$ axis.\n",
    "\n",
    "## **Poses** \n",
    "\n",
    "We will parameterize a trajectory as a sequence of poses, $p_0, p_1, p_2, \\dots, p_N$. Each pose is defined as a position (also called translation) and a rotation (also called orientation) in a fixed \"world\" frame. This world frame could be the initial pose of the robot, its charging station, some well known corner of a room, or another arbitrary position and orientation.\n",
    "\n",
    "Note that we have specified a point  $(x,y)$ with a rotation $\\theta$, within some world frame $w$. This means that the pose $(x=1,y=0,\\theta=10)$ lies exactly one meter ahead of the world origin and rotated from its $x$ axis by 10 degrees to the left (it is almost aligned with its $x$ axis), for example. It is important to be complete about our notation to avoid confusion! So let's call this transformation $X^w_0$, denoting the transformation **from** the world frame $w$ **to** the zero-th pose $p_0$.\n",
    "In this case we call $w$ the parent frame and $0$ the child frame.\n",
    "\n",
    "To build some intuition, what would be the transformation $X_w^0$?\n",
    "\n",
    "It would be the origin of the world frame $w$ in the frame of $op_0$. The transformation **from** $p_0$ to $w$. \n",
    "\n",
    "## **Transformations**\n",
    "\n",
    "So far, we have talked about poses in a world frame. We can continue our discussion and also talk about transformations between any frame to any other frame! As an example, we could ask where is the robot one second after the last time we have checked? Or in other words, _what is the transformation between time step $i$ to time step $i+1$?_ In general terms, it would be an object that denotes the motion of the robot. If we were standing at the pose of the robot at time $t$, then our transformation would tell us how to move to reflect the robot's pose at time $t+1$. We'll denote this kind of object as $X^i_{i+1}$. \n",
    "\n",
    "A transformation in two dimensions is a member of the \"special euclidean\" ($SE(2)$) group. This group is a group of matrices that encode rotations and translations. Each matrix $X \\in SO(2)$ (_\"$X$ in $SE(2)$\"_) is composed of a rotation matrix $R$ in the \"special orthogonal\" ($SO(2)$) group and a translation vector $\\mathbf{t}\\in\\mathbb{R}^2$. The rotation matrix is allowed to, obviously perhaps, rotate poses in space but not to scale or shear them. (Formally, it has to be orthogonal and have determinant with value 1.) This makes sense as a rotating robot often cannot change its shape. The translation vector takes on the shape of $[\\Delta x, \\Delta y]^\\top$, and encodes the motion of a robot along its $x$ and $y$ axes. The constraint on $\\mathbf{t}$ is such that its components are real numbers. \n",
    "\n",
    "If a robot moved by some $\\Delta x, \\Delta y$ meters and turned by $\\Delta \\theta$ radians, then we can ask ourselves a couple of questions:\n",
    "\n",
    "### Where would the robot origin be after the motion, with respect to its initial position?\n",
    "\n",
    "This is a simple case! We mark the robot's origin at time $i$ as the origin, and can see that the motion is exactly the transformation between the origin (robot position at time $i$) and its pose at time $i+1$ with respect to that initial position. Thus, the robot pose at time $i+1$ in the frame $i$, which is denoted with the $i$ superscripts and the $i+1$ subscripts, is the following.\n",
    "\n",
    "\n",
    "$$\\theta_{i+1}^i = \\Delta \\theta$$\n",
    "$$\\mathbf{t}^{i}_{i+1} = \\begin{bmatrix}\n",
    "\\Delta x\\\\\n",
    "\\Delta y\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "In our shorthand notation, we can write the rotation matrix and translation vector\n",
    "\n",
    "$$R_{i+1}^i = \\begin{bmatrix}\n",
    "\\cos(\\Delta \\theta) & \\sin(\\Delta \\theta)\\\\\n",
    "-\\sin(\\Delta \\theta) & \\cos(\\Delta \\theta)\\\\\n",
    "\\end{bmatrix}, \\ \\ \\ \n",
    "\\mathbf{t}_{i+1}^i = \\begin{bmatrix}\n",
    "\\Delta x\\\\\n",
    "\\Delta y\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$ X^i_{i+1} = \\begin{bmatrix}\n",
    "R^i_{i+1} & \\mathbf{t}^i_{i+1} \\\\\n",
    "\\mathbf{0} &1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### Where would any other point on the robot be, with respect to the robot's initial position, after the motion?\n",
    "\n",
    "When looking at a point away from the origin of the robot, like a position of a camera with respect to the robot origin that we denote $X^b_c$ (\"camera in the base frame\"), its new positions in the robot frame from time $i$ after the motion will not simply be the rotation and translation as specified by the motion. To compute the new position of the point on the robot, we'll first rotate it to the final robot configuration with the matrix multiplication $R^i_{i+1}X^b_c$ and then translate it with the robot translation $\\mathbf{t}^i_{i+1}$. This can be written as \n",
    "\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "{x^b_c}_{, i+1}\\\\\n",
    "{y^b_c}_{, i+1}\n",
    "\\end{bmatrix} = R^{i}_{i+1} \\begin{bmatrix}\n",
    "{x^b_c}_{, i}\\\\\n",
    "{y^b_c}_{, i}\n",
    "\\end{bmatrix} + \\mathbf{t}^i_{i+1}$$\n",
    "\n",
    "\n",
    "And in our shorthand:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "{x^b_c}_{, i+1}\\\\\n",
    "{y^b_c}_{, i+1}\\\\\n",
    "1\n",
    "\\end{bmatrix} = X^{i}_{i+1} \\begin{bmatrix}\n",
    "{x^b_c}_{, i}\\\\\n",
    "{y^b_c}_{, i}\\\\\n",
    "1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "### Where would the origin of the robot be, with respect to the world frame, after the motion that is specified in the robot frame.\n",
    "\n",
    "To answer question about the robot pose in the world frame, we first need to have information about its initial position in the world frame $X^w_i$. Let's assume that we have this information. As earlier, we also have information about the robot motion in its ows frame, which is $X^i_{i+1}$. We are interested in finding out the robot pose at time $i+1$, in the world frame, after its motion. This tranformation is denoted as $X^w_{i+1}$. I would argue that we have all the information that we need!\n",
    "\n",
    "For starters, we can find the orientation of the robot. The rotations simply add!\n",
    "\n",
    "$$\\theta_{i+1}^w = \\theta_i^w + \\Delta \\theta$$\n",
    "\n",
    "As for the translation, we are going to do an operation that may not seem trivial at first, but I believe that if you stare at it for a bit you'll see that it is logical.\n",
    "\n",
    "We'll \"transform\" the robot motion, that has been specified in its own frame, to \"begin\" at its pose as specified in the world frame.\n",
    "This is written as:\n",
    "\n",
    "$$X^w_{i+1} = X^w_{i} X^{i}_{i+1}$$\n",
    "\n",
    "Note how the subscripts and superscripts of the frames of reference match in a zig-zag fashion. This notation is very useful and reduces confusion! It has been adapted from the MIT Robotic Manipulation class https://manipulation.csail.mit.edu/.\n",
    "\n",
    "### Chaining Transformations.\n",
    "A cool thing that directly follows from the computation of $X^w_{i+1}$, is that we notice how we can add together a bunch of motions from a robot trajectory to compute a final robot pose. \n",
    "\n",
    "Say we are given a set of motions steps that occurred at times $i, i+1, i+2, i+3$, and also the initial robot configuration at time $i$ (call it $[x^w_i, y^w_i, \\theta^w_i]$ or $[X^w_i, \\theta^w_i]$). The we can compute the final robot orientation and translation as\n",
    "\n",
    "$$\\theta_{i+3}^w = \\theta_i^w + \\Delta \\theta^{i}_{i+1} + \\Delta \\theta^{i+1}_{i+2} + \\Delta \\theta^{i+2}_{i+3}$$\n",
    "\n",
    "$$X^w_{i+3} = X^w_{i} X^{i}_{i+1} X^{i+1}_{i+2} X^{i+2}_{i+3}$$\n",
    "\n",
    "Simple! Right? This is the way we can compute the robot pose after it moves in space, and all the information we have is its motion steps and initial position.\n",
    "\n",
    "\n",
    "<!-- $$ X^w_i = X^{i}_{i+1}X^w_{i+1}$$ -->\n",
    "\n",
    "\n",
    "### Inverse transformations\n",
    "\n",
    "Finally, we can also write down the _inverse_ transformation between two frames give a transformation between them. Specifically, if we have $X^i_{i+1}$, we'd like to know what is $X^{i+1}_i$, or \"if the robot would start at time $i+1$, how should it move to get to time $i$ (with respect to time $i+1$ as origin)?\".\n",
    "This operation will be useful later.\n",
    "\n",
    "$$\\theta_i^{i+1} = -\\theta_{i+1}^i$$\n",
    "\n",
    "$$ X^{i+1}_i = \\left( X^{i+1}_i \\right)^{-1} =  \\begin{bmatrix}\n",
    "(R^i_{i+1})^\\top & -(R^i_{i+1})^\\top \\mathbf{t}^i_{i+1} \\\\\n",
    "\\mathbf{0} &1\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Trajectory Python Class\n",
    "\n",
    "Phew! That was a lot of text. Let's shift gears and start implementing some code!\n",
    "\n",
    "Our code in this project will all be packaged withing the `Trajectory` class.\n",
    "\n",
    "We will use this class to keep track of robot trajectories and also optimize those when we have multiple measurements. What would we want to implement then? What are our inputs?\n",
    "\n",
    "Our inputs are\n",
    "1. A sequence of robot motions $[\\Delta x, \\Delta y, \\Delta \\theta]$.\n",
    "2. Observations of landmarks. We'll discuss those soon.\n",
    "\n",
    "Our outputs are:\n",
    "1. Optimized trajectory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a transformation from human-readable inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gtsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory():\n",
    "    def __init__(self) -> None:\n",
    "        # Noise.\n",
    "        self.ODOM_NOISE =     gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3, 0.3, 0.1]))\n",
    "        self.LANDMARK_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.03, 0.03, 0.03]))\n",
    "        self.PRIOR_NOISE =    gtsam.noiseModel.Diagonal.Sigmas(np.array([0.00003, 0.00003, 0.00001]))\n",
    "\n",
    "        # Landmarks.\n",
    "        self.landmarks = set()\n",
    "\n",
    "        # Measurements. Mapping nodes to RangeMeasurement's/\n",
    "        self.measurements = {}\n",
    "        \n",
    "        # Keep track of xy edges and build matrix C only after optimizing for angles.\n",
    "        self.edges = []\n",
    "\n",
    "        # Should we optimize after every edge addition?\n",
    "        self.online = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark observations.\n",
    "What and why\n",
    "\n",
    "Observation model. Adding observations to our class.\n",
    "Relating pose estimates via landmark observations (loop closures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating virtual measurements between poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dictionary relating odometry pose estimates to landmarks, and a relative pose between an odometry estimate and some landmark return a list of relative poses between the other nodes that have seen this landmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Primer\n",
    "\n",
    "In this section we are not going to dive too deep into the background of optimization theory. In fact, we will almost completely leave the actual optimization of the pose graph  (the trajectory optimization) as a black box.\n",
    "\n",
    "It is helpful, however, to understand what optimization is and how it could be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares line fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Optimization.\n",
    "\n",
    "Formulation of cost function and analogy to least squares linear regression\n",
    "\n",
    "provide code for optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
